{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev460469908\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/age_data\",\n",
    "    target_cols=[\"Age\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyafq_bundles = [\n",
    "    c for c in columns\n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "pyafq_bundles = [\n",
    "    [c] for c in np.unique([col[1] for col in pyafq_bundles])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pyafq_bundles = afqi.select_groups(\n",
    "    X,\n",
    "    pyafq_bundles,\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 10000)\n",
      "(77, 9000)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(len(label_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    c for c in columns \n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))\n",
    "\n",
    "X_md_fa = afqi.select_groups(\n",
    "    X_pyafq_bundles,\n",
    "    [[\"fa\"], [\"md\"]],\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 10000)\n",
      "(77, 9000)\n",
      "(77, 3600)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(X_md_fa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups_md_fa = groups[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10,\n",
    "                   trim_nodes=0,\n",
    "                   square_features=False):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "\n",
    "    if trim_nodes > 0:\n",
    "        grp_mask = np.zeros_like(groups_md_fa[0], dtype=bool)\n",
    "        grp_mask[trim_nodes:-trim_nodes] = True\n",
    "        X_mask = np.concatenate([grp_mask] * len(groups_md_fa))\n",
    "\n",
    "        groups_trim = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for grp in groups_md_fa:\n",
    "            stop_idx = start_idx + len(grp) - 2 * trim_nodes\n",
    "            groups_trim.append(np.arange(start_idx, stop_idx))\n",
    "            start_idx += len(grp) - 2 * trim_nodes\n",
    "            \n",
    "        X_trim = X_md_fa[:, X_mask]\n",
    "    elif trim_nodes == 0:\n",
    "        groups_trim = [grp for grp in groups_md_fa]\n",
    "        X_trim = np.copy(X_md_fa)\n",
    "    else:\n",
    "        raise ValueError(\"trim_nodes must be non-negative.\")\n",
    "        \n",
    "    if square_features:\n",
    "        _n_samples, _n_features = X_trim.shape\n",
    "        X_trim = np.hstack([X_trim, np.square(X_trim)])\n",
    "        groups_trim = [np.concatenate([g, g + _n_features]) for g in groups_trim]\n",
    "    \n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    \n",
    "    pipe_skopt = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LassoCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"n_alphas\": 50,\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 28,\n",
    "            \"max_iter\": 500,\n",
    "        },\n",
    "        verbose=0,\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "        target_transform_func=target_transform_func,\n",
    "        target_transform_inverse_func=target_transform_inverse_func,\n",
    "    )\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_r2\": r2_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_r2\": r2_score(y_train, pipe_skopt.predict(X_train)),\n",
    "        }\n",
    "        \n",
    "        if ensembler is None:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.alpha_\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].alpha_\n",
    "        else:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "        \n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:01.427498\n",
      "CV index [  1], Elapsed time:  0:00:00.233336\n",
      "CV index [  2], Elapsed time:  0:00:00.218221\n",
      "CV index [  3], Elapsed time:  0:00:00.237239\n",
      "CV index [  4], Elapsed time:  0:00:00.238746\n",
      "CV index [  5], Elapsed time:  0:00:00.235029\n",
      "CV index [  6], Elapsed time:  0:00:00.237095\n",
      "CV index [  7], Elapsed time:  0:00:00.235605\n",
      "CV index [  8], Elapsed time:  0:00:00.226557\n",
      "CV index [  9], Elapsed time:  0:00:00.246675\n",
      "CV index [  0], Elapsed time:  0:00:00.233808\n",
      "CV index [  1], Elapsed time:  0:00:00.216417\n",
      "CV index [  2], Elapsed time:  0:00:00.224500\n",
      "CV index [  3], Elapsed time:  0:00:00.215640\n",
      "CV index [  4], Elapsed time:  0:00:00.221725\n",
      "CV index [  5], Elapsed time:  0:00:00.225968\n",
      "CV index [  6], Elapsed time:  0:00:00.202839\n",
      "CV index [  7], Elapsed time:  0:00:00.236909\n",
      "CV index [  8], Elapsed time:  0:00:00.236790\n",
      "CV index [  9], Elapsed time:  0:00:00.231940\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "trim_nodes = 0\n",
    "results[f\"bagging_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=PCA,\n",
    "    shuffle=False,\n",
    "    trim_nodes=trim_nodes, square_features=False,\n",
    ")\n",
    "\n",
    "results[f\"bagging_target_transform_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=PCA,\n",
    "    shuffle=False,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    "    trim_nodes=trim_nodes, square_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bagging_pure_lasso_trim0', 'bagging_target_transform_pure_lasso_trim0'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_pure_lasso_trim0 test  MAE 4.728637000936456\n",
      "bagging_pure_lasso_trim0 train MAE 3.502354671105497\n",
      "bagging_pure_lasso_trim0 test  R2  0.5197810932713327\n",
      "bagging_pure_lasso_trim0 train R2  0.7812728285588396\n",
      "bagging_target_transform_pure_lasso_trim0 test  MAE 3.7256484307018063\n",
      "bagging_target_transform_pure_lasso_trim0 train MAE 2.330864757121073\n",
      "bagging_target_transform_pure_lasso_trim0 test  R2  0.5366909868584032\n",
      "bagging_target_transform_pure_lasso_trim0 train R2  0.7362577556743801\n"
     ]
    }
   ],
   "source": [
    "for key, res in results.items():\n",
    "    test_mae = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_mae = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    test_r2 = [cvr[\"test_r2\"] for cvr in res[0].values()]\n",
    "    train_r2 = [cvr[\"train_r2\"] for cvr in res[0].values()]\n",
    "\n",
    "    print(key, \"test  MAE\", np.mean(test_mae))\n",
    "    print(key, \"train MAE\", np.mean(train_mae))\n",
    "    print(key, \"test  R2 \", np.mean(test_r2))\n",
    "    print(key, \"train R2 \", np.mean(train_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"age_regression_pcr_lasso.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
