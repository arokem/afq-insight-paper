{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import logging\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=28,\n",
    "    threads_per_worker=8,\n",
    "    silence_logs=logging.DEBUG\n",
    ")\n",
    "\n",
    "client = Client(cluster, heartbeat_interval=10000)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/age_data\",\n",
    "    target_cols=[\"Age\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyafq_bundles = [\n",
    "    c for c in columns\n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "pyafq_bundles = [\n",
    "    [c] for c in np.unique([col[1] for col in pyafq_bundles])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pyafq_bundles = afqi.select_groups(\n",
    "    X,\n",
    "    pyafq_bundles,\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(len(label_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    c for c in columns \n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))\n",
    "\n",
    "X_md_fa = afqi.select_groups(\n",
    "    X_pyafq_bundles,\n",
    "    [[\"fa\"], [\"md\"]],\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(X_md_fa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups_md_fa = groups[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10,\n",
    "                   trim_nodes=0,\n",
    "                   square_features=False):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "\n",
    "    if trim_nodes > 0:\n",
    "        grp_mask = np.zeros_like(groups_md_fa[0], dtype=bool)\n",
    "        grp_mask[trim_nodes:-trim_nodes] = True\n",
    "        X_mask = np.concatenate([grp_mask] * len(groups_md_fa))\n",
    "\n",
    "        groups_trim = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for grp in groups_md_fa:\n",
    "            stop_idx = start_idx + len(grp) - 2 * trim_nodes\n",
    "            groups_trim.append(np.arange(start_idx, stop_idx))\n",
    "            start_idx += len(grp) - 2 * trim_nodes\n",
    "            \n",
    "        X_trim = X_md_fa[:, X_mask]\n",
    "    elif trim_nodes == 0:\n",
    "        groups_trim = [grp for grp in groups_md_fa]\n",
    "        X_trim = np.copy(X_md_fa)\n",
    "    else:\n",
    "        raise ValueError(\"trim_nodes must be non-negative.\")\n",
    "        \n",
    "    if square_features:\n",
    "        _n_samples, _n_features = X_trim.shape\n",
    "        X_trim = np.hstack([X_trim, np.square(X_trim)])\n",
    "        groups_trim = [np.concatenate([g, g + _n_features]) for g in groups_trim]\n",
    "    \n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    pipe_skopt = afqi.make_afq_regressor_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        use_cv_estimator=True,\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        groups=groups_trim,\n",
    "        verbose=0,\n",
    "        pipeline_verbosity=False,\n",
    "        tuning_strategy=\"bayes\",\n",
    "        cv=3,\n",
    "        n_bayes_points=9,\n",
    "        n_jobs=28,\n",
    "        l1_ratio=[0.0, 1.0],\n",
    "        eps=5e-2,\n",
    "        n_alphas=100,\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "        target_transform_func=target_transform_func,\n",
    "        target_transform_inverse_func=target_transform_inverse_func,\n",
    "    )\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        with joblib.parallel_backend(\"dask\"):\n",
    "            pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_r2\": r2_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_r2\": r2_score(y_train, pipe_skopt.predict(X_train)),\n",
    "        }\n",
    "        \n",
    "        if ((target_transform_func is not None)\n",
    "            or (target_transform_inverse_func is not None)):\n",
    "            cv_results[cv_idx][\"coefs\"] = [\n",
    "                est.coef_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"alpha\"] = [\n",
    "                est.alpha_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"l1_ratio\"] = [\n",
    "                est.l1_ratio_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "        else:\n",
    "            cv_results[cv_idx][\"coefs\"] = [\n",
    "                est.coef_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"alpha\"] = [\n",
    "                est.alpha_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"l1_ratio\"] = [\n",
    "                est.l1_ratio_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "        \n",
    "        if ensembler is None:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"optimizer\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.bayes_optimizer_                \n",
    "            else:\n",
    "                cv_results[cv_idx][\"optimizer\"] = pipe_skopt.named_steps[\"estimate\"].bayes_optimizer_\n",
    "\n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "trim_nodes = 0\n",
    "results[f\"bagging_target_transform_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=False,\n",
    "    ensembler=\"serial-bagging\", shuffle=False, n_estimators=20,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    "    trim_nodes=trim_nodes, square_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"age_regression_paper.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    test_accuracies = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_accuracies = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    print(key, \"test\", np.mean(test_accuracies))\n",
    "    print(key, \"train\", np.mean(train_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
