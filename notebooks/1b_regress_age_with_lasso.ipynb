{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35713 instead\n",
      "  http_address[\"port\"], self.http_server.port\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:38277\n",
      "distributed.scheduler - INFO -   dashboard at:           127.0.0.1:35713\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41639'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33573'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40721'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43521'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44927'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42013'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42775'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33475'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36083'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38601'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40565'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45877'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38163'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44343'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43945'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33283'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43785'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34763'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33555'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44379'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40059'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42067'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46467'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42847'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43267'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36597'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43495'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32863'\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:43345', name: 25, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43345\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36439', name: 2, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36439\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:42641', name: 1, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42641\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:33717', name: 18, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33717\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:34139', name: 5, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34139\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39779', name: 10, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39779\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:34919', name: 8, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34919\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:35797', name: 16, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35797\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38639', name: 21, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38639\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41415', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41415\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:42345', name: 20, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42345\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:43567', name: 12, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43567\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39431', name: 19, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39431\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39413', name: 23, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39413\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:42103', name: 4, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42103\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:40017', name: 26, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40017\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:33969', name: 0, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33969\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36921', name: 24, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36921\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38209', name: 7, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38209\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:40943', name: 13, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40943\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:45907', name: 22, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45907\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:44633', name: 14, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44633\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36693', name: 27, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36693\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:45127', name: 17, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45127\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:42611', name: 6, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42611\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38549', name: 11, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38549\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:34227', name: 15, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34227\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38197', name: 9, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38197\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-d77a18c6-3f0a-11eb-b0ad-b7504a8ec45b\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:35713/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import logging\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=28,\n",
    "    threads_per_worker=8,\n",
    "    silence_logs=logging.DEBUG\n",
    ")\n",
    "\n",
    "client = Client(cluster, heartbeat_interval=10000)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev460469908\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/age_data\",\n",
    "    target_cols=[\"Age\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_md_fa = afqi.select_groups(X, [[\"fa\"], [\"md\"]], label_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_md_fa = groups[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "\n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    \n",
    "    pipe = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LassoCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"n_alphas\": 200,\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 28,\n",
    "            \"max_iter\": 5000,\n",
    "        },\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "        target_transform_func=target_transform_func,\n",
    "        target_transform_inverse_func=target_transform_inverse_func,\n",
    "    )\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_md_fa, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_md_fa[train_idx], X_md_fa[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        with joblib.parallel_backend(\"dask\"):\n",
    "            pipe.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe.predict(X_train))\n",
    "        }\n",
    "        \n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:10.168060\n",
      "CV index [  1], Elapsed time:  0:00:06.457292\n",
      "CV index [  2], Elapsed time:  0:00:05.296155\n",
      "CV index [  3], Elapsed time:  0:00:05.386212\n",
      "CV index [  4], Elapsed time:  0:00:10.290863\n",
      "CV index [  5], Elapsed time:  0:00:07.727080\n",
      "CV index [  6], Elapsed time:  0:00:09.348220\n",
      "CV index [  7], Elapsed time:  0:00:04.322436\n",
      "CV index [  8], Elapsed time:  0:00:07.867198\n",
      "CV index [  9], Elapsed time:  0:00:05.842299\n",
      "CV index [ 10], Elapsed time:  0:00:05.344998\n",
      "CV index [ 11], Elapsed time:  0:00:07.970502\n",
      "CV index [ 12], Elapsed time:  0:00:11.064658\n",
      "CV index [ 13], Elapsed time:  0:00:06.692730\n",
      "CV index [ 14], Elapsed time:  0:00:06.100153\n",
      "CV index [ 15], Elapsed time:  0:00:04.179891\n",
      "CV index [ 16], Elapsed time:  0:00:06.950540\n",
      "CV index [ 17], Elapsed time:  0:00:05.878240\n",
      "CV index [ 18], Elapsed time:  0:00:06.580265\n",
      "CV index [ 19], Elapsed time:  0:00:06.618419\n",
      "CV index [ 20], Elapsed time:  0:00:09.707801\n",
      "CV index [ 21], Elapsed time:  0:00:05.609096\n",
      "CV index [ 22], Elapsed time:  0:00:06.925310\n",
      "CV index [ 23], Elapsed time:  0:00:06.847896\n",
      "CV index [ 24], Elapsed time:  0:00:08.644211\n",
      "CV index [ 25], Elapsed time:  0:00:06.369448\n",
      "CV index [ 26], Elapsed time:  0:00:06.773697\n",
      "CV index [ 27], Elapsed time:  0:00:07.793589\n",
      "CV index [ 28], Elapsed time:  0:00:10.585322\n",
      "CV index [ 29], Elapsed time:  0:00:06.100724\n",
      "CV index [ 30], Elapsed time:  0:00:06.220367\n",
      "CV index [ 31], Elapsed time:  0:00:04.309931\n",
      "CV index [ 32], Elapsed time:  0:00:08.881366\n",
      "CV index [ 33], Elapsed time:  0:00:05.414286\n",
      "CV index [ 34], Elapsed time:  0:00:04.569865\n",
      "CV index [ 35], Elapsed time:  0:00:05.614332\n",
      "CV index [ 36], Elapsed time:  0:00:08.500160\n",
      "CV index [ 37], Elapsed time:  0:00:06.825752\n",
      "CV index [ 38], Elapsed time:  0:00:07.905896\n",
      "CV index [ 39], Elapsed time:  0:00:04.923976\n",
      "CV index [ 40], Elapsed time:  0:00:09.686556\n",
      "CV index [ 41], Elapsed time:  0:00:03.384550\n",
      "CV index [ 42], Elapsed time:  0:00:06.268876\n",
      "CV index [ 43], Elapsed time:  0:00:05.035413\n",
      "CV index [ 44], Elapsed time:  0:00:09.467598\n",
      "CV index [ 45], Elapsed time:  0:00:04.660719\n",
      "CV index [ 46], Elapsed time:  0:00:05.042364\n",
      "CV index [ 47], Elapsed time:  0:00:05.277466\n",
      "CV index [ 48], Elapsed time:  0:00:11.798454\n",
      "CV index [ 49], Elapsed time:  0:00:07.513829\n",
      "CV index [  0], Elapsed time:  0:00:11.317126\n",
      "CV index [  1], Elapsed time:  0:00:03.415826\n",
      "CV index [  2], Elapsed time:  0:00:06.500084\n",
      "CV index [  3], Elapsed time:  0:00:04.543963\n",
      "CV index [  4], Elapsed time:  0:00:04.020041\n",
      "CV index [  5], Elapsed time:  0:00:02.990223\n",
      "CV index [  6], Elapsed time:  0:00:05.347357\n",
      "CV index [  7], Elapsed time:  0:00:03.244042\n",
      "CV index [  8], Elapsed time:  0:00:05.080399\n",
      "CV index [  9], Elapsed time:  0:00:03.524442\n",
      "CV index [ 10], Elapsed time:  0:00:08.633676\n",
      "CV index [ 11], Elapsed time:  0:00:05.846984\n",
      "CV index [ 12], Elapsed time:  0:00:02.754408\n",
      "CV index [ 13], Elapsed time:  0:00:03.300311\n",
      "CV index [ 14], Elapsed time:  0:00:06.710355\n",
      "CV index [ 15], Elapsed time:  0:00:02.501214\n",
      "CV index [ 16], Elapsed time:  0:00:03.780448\n",
      "CV index [ 17], Elapsed time:  0:00:04.048006\n",
      "CV index [ 18], Elapsed time:  0:00:06.531172\n",
      "CV index [ 19], Elapsed time:  0:00:04.028494\n",
      "CV index [ 20], Elapsed time:  0:00:03.457017\n",
      "CV index [ 21], Elapsed time:  0:00:05.783589\n",
      "CV index [ 22], Elapsed time:  0:00:05.203392\n",
      "CV index [ 23], Elapsed time:  0:00:02.844856\n",
      "CV index [ 24], Elapsed time:  0:00:03.744624\n",
      "CV index [ 25], Elapsed time:  0:00:05.830852\n",
      "CV index [ 26], Elapsed time:  0:00:07.907978\n",
      "CV index [ 27], Elapsed time:  0:00:05.092723\n",
      "CV index [ 28], Elapsed time:  0:00:03.920912\n",
      "CV index [ 29], Elapsed time:  0:00:05.089832\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"no_power_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=5, power_transformer=False, shuffle=False\n",
    ")\n",
    "results[\"shuffle_no_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=3, power_transformer=False, shuffle=True\n",
    ")\n",
    "\n",
    "# with open(\"age_regression_lasso.pkl\", \"rb\") as fp:\n",
    "#     results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:11.569760\n",
      "CV index [  1], Elapsed time:  0:00:06.735639\n",
      "CV index [  2], Elapsed time:  0:00:05.005268\n",
      "CV index [  3], Elapsed time:  0:00:04.278545\n",
      "CV index [  4], Elapsed time:  0:00:11.160258\n",
      "CV index [  5], Elapsed time:  0:00:08.647319\n",
      "CV index [  6], Elapsed time:  0:00:06.863602\n",
      "CV index [  7], Elapsed time:  0:00:06.043430\n",
      "CV index [  8], Elapsed time:  0:00:09.846008\n",
      "CV index [  9], Elapsed time:  0:00:05.781704\n",
      "CV index [ 10], Elapsed time:  0:00:05.195436\n",
      "CV index [ 11], Elapsed time:  0:00:05.273486\n",
      "CV index [ 12], Elapsed time:  0:00:08.276016\n",
      "CV index [ 13], Elapsed time:  0:00:05.775949\n",
      "CV index [ 14], Elapsed time:  0:00:06.168996\n",
      "CV index [ 15], Elapsed time:  0:00:05.549727\n",
      "CV index [ 16], Elapsed time:  0:00:09.081567\n",
      "CV index [ 17], Elapsed time:  0:00:12.931280\n",
      "CV index [ 18], Elapsed time:  0:00:08.848602\n",
      "CV index [ 19], Elapsed time:  0:00:05.061774\n",
      "CV index [ 20], Elapsed time:  0:00:08.563393\n",
      "CV index [ 21], Elapsed time:  0:00:10.679583\n",
      "CV index [ 22], Elapsed time:  0:00:11.725721\n",
      "CV index [ 23], Elapsed time:  0:00:03.914665\n",
      "CV index [ 24], Elapsed time:  0:00:11.625907\n",
      "CV index [ 25], Elapsed time:  0:00:05.913433\n",
      "CV index [ 26], Elapsed time:  0:00:08.063293\n",
      "CV index [ 27], Elapsed time:  0:00:05.113361\n",
      "CV index [ 28], Elapsed time:  0:00:08.079036\n",
      "CV index [ 29], Elapsed time:  0:00:08.078943\n",
      "CV index [ 30], Elapsed time:  0:00:05.223299\n",
      "CV index [ 31], Elapsed time:  0:00:03.981945\n",
      "CV index [ 32], Elapsed time:  0:00:11.362245\n",
      "CV index [ 33], Elapsed time:  0:00:05.071077\n",
      "CV index [ 34], Elapsed time:  0:00:05.286296\n",
      "CV index [ 35], Elapsed time:  0:00:04.815638\n",
      "CV index [ 36], Elapsed time:  0:00:10.645683\n",
      "CV index [ 37], Elapsed time:  0:00:05.981826\n",
      "CV index [ 38], Elapsed time:  0:00:06.116035\n",
      "CV index [ 39], Elapsed time:  0:00:04.899508\n",
      "CV index [ 40], Elapsed time:  0:00:10.273790\n",
      "CV index [ 41], Elapsed time:  0:00:07.760037\n",
      "CV index [ 42], Elapsed time:  0:00:09.242739\n",
      "CV index [ 43], Elapsed time:  0:00:05.262605\n",
      "CV index [ 44], Elapsed time:  0:00:10.994490\n",
      "CV index [ 45], Elapsed time:  0:00:06.953455\n",
      "CV index [ 46], Elapsed time:  0:00:07.632876\n",
      "CV index [ 47], Elapsed time:  0:00:05.729096\n",
      "CV index [ 48], Elapsed time:  0:00:09.427990\n",
      "CV index [ 49], Elapsed time:  0:00:09.518143\n",
      "CV index [  0], Elapsed time:  0:00:02.891481\n",
      "CV index [  1], Elapsed time:  0:00:03.543841\n",
      "CV index [  2], Elapsed time:  0:00:07.765522\n",
      "CV index [  3], Elapsed time:  0:00:04.310160\n",
      "CV index [  4], Elapsed time:  0:00:04.276881\n",
      "CV index [  5], Elapsed time:  0:00:04.375356\n",
      "CV index [  6], Elapsed time:  0:00:05.922291\n",
      "CV index [  7], Elapsed time:  0:00:04.952692\n",
      "CV index [  8], Elapsed time:  0:00:04.222262\n",
      "CV index [  9], Elapsed time:  0:00:03.940995\n",
      "CV index [ 10], Elapsed time:  0:00:05.819955\n",
      "CV index [ 11], Elapsed time:  0:00:03.922065\n",
      "CV index [ 12], Elapsed time:  0:00:02.992335\n",
      "CV index [ 13], Elapsed time:  0:00:03.126620\n",
      "CV index [ 14], Elapsed time:  0:00:08.453597\n",
      "CV index [ 15], Elapsed time:  0:00:04.117533\n",
      "CV index [ 16], Elapsed time:  0:00:02.691448\n",
      "CV index [ 17], Elapsed time:  0:00:04.644991\n",
      "CV index [ 18], Elapsed time:  0:00:08.537398\n",
      "CV index [ 19], Elapsed time:  0:00:08.042549\n",
      "CV index [ 20], Elapsed time:  0:00:03.904791\n",
      "CV index [ 21], Elapsed time:  0:00:04.600717\n",
      "CV index [ 22], Elapsed time:  0:00:07.619419\n",
      "CV index [ 23], Elapsed time:  0:00:04.955956\n",
      "CV index [ 24], Elapsed time:  0:00:03.404293\n",
      "CV index [ 25], Elapsed time:  0:00:03.483604\n",
      "CV index [ 26], Elapsed time:  0:00:08.125984\n",
      "CV index [ 27], Elapsed time:  0:00:04.657751\n",
      "CV index [ 28], Elapsed time:  0:00:04.617575\n",
      "CV index [ 29], Elapsed time:  0:00:03.394597\n"
     ]
    }
   ],
   "source": [
    "results[\"target_log_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=5, power_transformer=False, shuffle=False,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    ")\n",
    "\n",
    "results[\"shuffle_target_log_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=3, power_transformer=False, shuffle=True,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"age_regression_lasso.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['no_power_transform', 'shuffle_no_transform', 'target_log_transform', 'shuffle_target_log_transform'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_power_transform mean 4.911651713980643\n",
      "no_power_transform std 2.1794284381788485\n",
      "shuffle_no_transform mean 9.831946509985348\n",
      "shuffle_no_transform std 2.107599601843023\n",
      "target_log_transform mean 3.7080493910409933\n",
      "target_log_transform std 2.109180013045811\n",
      "shuffle_target_log_transform mean 7.67703843451133\n",
      "shuffle_target_log_transform std 1.93403821029267\n"
     ]
    }
   ],
   "source": [
    "for key, res in results.items():\n",
    "    test_accuracies = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_accuracies = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    print(key, \"mean\", np.mean(test_accuracies))\n",
    "    print(key, \"std\", np.std(test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def mean_over_combinations(results):\n",
    "    length = len(results)\n",
    "    mean_results = {}\n",
    "    for r in range(1, length + 1):\n",
    "        mean_results[r] = [\n",
    "            np.mean([res[\"yhat\"].values for res in comb], axis=0)\n",
    "            for comb in itertools.combinations(results, r=r)\n",
    "        ]\n",
    "        \n",
    "    return mean_results\n",
    "\n",
    "def mae_over_combinations(results):\n",
    "    mean_results = mean_over_combinations(results)\n",
    "    mean_mae = []\n",
    "    for r in mean_results.keys():\n",
    "        mean_mae += [\n",
    "            {\n",
    "                \"n_repeats\": r,\n",
    "                \"mae\": median_absolute_error(results[0][\"y_true\"].values, res)\n",
    "            } for res in mean_results[r]\n",
    "        ]\n",
    "        \n",
    "    return pd.DataFrame(mean_mae)\n",
    "\n",
    "def get_mae_ensemble_dataframe(cv_results, y_true):    \n",
    "    test_preds = {\n",
    "        idx: pd.Series(\n",
    "            data=cvr[\"y_pred\"],\n",
    "            index=cvr[\"test_idx\"],\n",
    "            name=\"yhat\"\n",
    "        )\n",
    "        for idx, cvr in cv_results.items()\n",
    "    }\n",
    "    \n",
    "    df_ytest = {\n",
    "        idx: pd.DataFrame(test_preds[idx]).merge(\n",
    "            pd.DataFrame(y_true, columns=[\"y_true\"]),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\"\n",
    "        ) for idx in test_preds.keys()\n",
    "    }\n",
    "    \n",
    "    mae_scores = [\n",
    "        median_absolute_error(_df[\"y_true\"].values, _df[\"yhat\"].values)\n",
    "        for _df in df_ytest.values()\n",
    "    ]\n",
    "    \n",
    "    repeats = [\n",
    "        pd.concat([df_ytest[i] for i in range(x * 10, (x + 1) * 10)]).sort_index()\n",
    "        for x in range(len(cv_results) // 10)\n",
    "    ]\n",
    "    \n",
    "    return mae_over_combinations(repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mae = {\n",
    "    key: get_mae_ensemble_dataframe(res[0], y)\n",
    "    for key, res in results.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"n_repeats\", y=\"mae\", data=df_mae[\"no_power_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"n_repeats\", y=\"mae\", data=df_mae[\"target_log_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results[\"bagging\"] = get_cv_results(\n",
    "#     n_splits=10, n_repeats=1, power_transformer=False,\n",
    "#     ensembler=\"serial-bagging\", shuffle=False, n_estimators=20,\n",
    "# )\n",
    "# results[\"bagging_shuffle\"] = get_cv_results(\n",
    "#     n_splits=10, n_repeats=1, power_transformer=False,\n",
    "#     ensembler=\"serial-bagging\", shuffle=True, n_estimators=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results[\"bagging_target_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=False,\n",
    "    ensembler=\"serial-bagging\", shuffle=False, n_estimators=20,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    ")\n",
    "results[\"bagging_shuffle_target_transform\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=False,\n",
    "    ensembler=\"serial-bagging\", shuffle=True, n_estimators=10,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    test_accuracies = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_accuracies = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    print(key, \"test\", np.mean(test_accuracies))\n",
    "    print(key, \"train\", np.mean(train_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"age_regression.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
