{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from dask.distributed import Client, LocalCluster\n",
    "# import logging\n",
    "\n",
    "# cluster = LocalCluster(\n",
    "#     n_workers=28,\n",
    "#     threads_per_worker=8,\n",
    "#     silence_logs=logging.DEBUG\n",
    "# )\n",
    "\n",
    "# client = Client(cluster, heartbeat_interval=10000)\n",
    "# print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev2565515056\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import groupyr as gpr\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from groupyr.transform import GroupRemover, GroupExtractor\n",
    "from groupyr.decomposition import GroupPCA\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, group_names, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/age_data\",\n",
    "    target_cols=[\"Age\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyafq_bundles = [\n",
    "    c for c in columns\n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "pyafq_bundles = [\n",
    "    [c] for c in np.unique([col[1] for col in pyafq_bundles])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = GroupRemover(\n",
    "    select=[\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"],\n",
    "    groups=groups,\n",
    "    group_names=group_names,\n",
    ")\n",
    "X_pyafq_bundles = gr.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 10000)\n",
      "(77, 9000)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(len(label_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\n",
    "    grp for grp in group_names\n",
    "    if \"Cingulum Hippocampus\" not in grp[1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge = GroupExtractor(\n",
    "    select=[\"fa\", \"md\"],\n",
    "    groups=groups[:90],\n",
    "    group_names=group_names\n",
    ")\n",
    "X_md_fa = ge.fit_transform(X_pyafq_bundles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 10000)\n",
      "(77, 9000)\n",
      "(77, 3600)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(X_md_fa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups_md_fa = groups[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "\n",
    "    X_trim = np.copy(X_md_fa)\n",
    "            \n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    gpca = GroupPCA(groups=groups_md_fa)\n",
    "    \n",
    "    cv_results = {}\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        groups_pca = gpca.fit(imputer.fit_transform(X_train)).groups_out_\n",
    "\n",
    "        pipe_skopt = afqi.make_afq_regressor_pipeline(\n",
    "            imputer_kwargs={\"strategy\": \"median\"},\n",
    "            use_cv_estimator=True,\n",
    "            power_transformer=power_transformer,\n",
    "            scaler=\"standard\",\n",
    "            groups=groups_pca,\n",
    "            verbose=0,\n",
    "            pipeline_verbosity=False,\n",
    "            tuning_strategy=\"bayes\",\n",
    "            cv=3,\n",
    "            n_bayes_points=9,\n",
    "            n_jobs=28,\n",
    "            l1_ratio=[0.0, 1.0],\n",
    "            eps=5e-2,\n",
    "            n_alphas=100,\n",
    "            power_transformer_kwargs={\n",
    "                \"groups\": groups_md_fa\n",
    "            },\n",
    "            ensemble_meta_estimator=ensembler,\n",
    "            ensemble_meta_estimator_kwargs={\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"n_jobs\": 1,\n",
    "                \"oob_score\": True,\n",
    "                \"random_state\": 1729,\n",
    "            },\n",
    "            target_transform_func=target_transform_func,\n",
    "            target_transform_inverse_func=target_transform_inverse_func,\n",
    "        )\n",
    "\n",
    "        pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_r2\": r2_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_r2\": r2_score(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"pca_components\": pipe_skopt.named_steps[\"power_transform\"].components_,\n",
    "        }\n",
    "        \n",
    "        if ((target_transform_func is not None)\n",
    "            or (target_transform_inverse_func is not None)):\n",
    "            cv_results[cv_idx][\"coefs\"] = [\n",
    "                est.coef_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"alpha\"] = [\n",
    "                est.alpha_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"l1_ratio\"] = [\n",
    "                est.l1_ratio_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "            ]\n",
    "        else:\n",
    "            cv_results[cv_idx][\"coefs\"] = [\n",
    "                est.coef_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"alpha\"] = [\n",
    "                est.alpha_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"l1_ratio\"] = [\n",
    "                est.l1_ratio_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "        \n",
    "        if ensembler is None:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"optimizer\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.bayes_optimizer_                \n",
    "            else:\n",
    "                cv_results[cv_idx][\"optimizer\"] = pipe_skopt.named_steps[\"estimate\"].bayes_optimizer_\n",
    "\n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:13:58.697415\n",
      "CV index [  1], Elapsed time:  0:14:25.753417\n",
      "CV index [  2], Elapsed time:  0:14:39.390576\n",
      "CV index [  3], Elapsed time:  0:15:02.288144\n",
      "CV index [  4], Elapsed time:  0:14:44.287568\n",
      "CV index [  5], Elapsed time:  0:14:54.976586\n",
      "CV index [  6], Elapsed time:  0:14:50.852941\n",
      "CV index [  7], Elapsed time:  0:14:11.045175\n",
      "CV index [  8], Elapsed time:  0:10:35.455490\n",
      "CV index [  9], Elapsed time:  0:10:29.386885\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "results[\"bagging_target_transform_group_pca\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=GroupPCA,\n",
    "    ensembler=\"serial-bagging\", shuffle=False, n_estimators=20,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bagging_target_transform_group_pca'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_target_transform_group_pca test 4.203163993866996\n",
      "bagging_target_transform_group_pca test 0.4590716909053481\n"
     ]
    }
   ],
   "source": [
    "for key, res in results.items():\n",
    "    test_mae = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_mae = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    test_r2 = [cvr[\"test_r2\"] for cvr in res[0].values()]\n",
    "    train_r2 = [cvr[\"train_r2\"] for cvr in res[0].values()]\n",
    "    print(key, \"test\", np.mean(test_mae))\n",
    "    print(key, \"test\", np.mean(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"age_regression_group_pca.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
