{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42841 instead\n",
      "  http_address[\"port\"], self.http_server.port\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:46817\n",
      "distributed.scheduler - INFO -   dashboard at:           127.0.0.1:42841\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33355'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37043'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43735'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44543'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38867'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40687'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36923'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34025'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41145'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42375'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35971'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36203'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44731'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34933'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36971'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39829'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33079'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40067'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43173'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34639'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38397'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42657'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44759'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35275'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44513'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43493'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42401'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44885'\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:37345', name: 14, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37345\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:40423', name: 5, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40423\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:34991', name: 22, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34991\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39467', name: 1, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39467\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:46027', name: 7, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46027\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39809', name: 0, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39809\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:35511', name: 17, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35511\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39415', name: 26, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39415\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39483', name: 18, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39483\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:33969', name: 4, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33969\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36113', name: 24, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36113\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41777', name: 27, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41777\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41595', name: 2, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41595\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:43507', name: 20, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43507\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:43893', name: 16, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43893\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36205', name: 12, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36205\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:35699', name: 9, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35699\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41507', name: 19, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41507\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38681', name: 10, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38681\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:40251', name: 6, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40251\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36465', name: 21, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36465\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:34559', name: 13, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34559\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:35839', name: 15, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35839\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38543', name: 8, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38543\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41675', name: 11, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41675\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:33861', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33861\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38515', name: 25, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38515\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36671', name: 23, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36671\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-9e37a422-64cc-11eb-b7bf-4f23f7815882\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:42841/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import logging\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=28,\n",
    "    threads_per_worker=8,\n",
    "    silence_logs=logging.DEBUG\n",
    ")\n",
    "\n",
    "client = Client(cluster, heartbeat_interval=10000)\n",
    "\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev460469908\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hbn_regression_pure_lasso.pkl\", \"rb\") as fp:\n",
    "    results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bagging_pure_lasso_trim0', 'bagging_target_transform_pure_lasso_trim0'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/hbn_data\",\n",
    "    target_cols=[\"Age\"],\n",
    "    index_col=\"EID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1597, 3600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_csv(\"../data/raw/hbn_data/subjects.csv\").drop(axis=\"rows\", index=0)\n",
    "df_y = df_y[[\"EID\", \"Age\"]]\n",
    "df_y = df_y.set_index(\"EID\", drop=True)\n",
    "df_subs = pd.DataFrame(index=subjects)\n",
    "df_subs = df_subs.merge(df_y, how=\"left\", left_index=True, right_index=True)\n",
    "y = df_subs[\"Age\"].astype(np.float64).values\n",
    "nan_mask = np.logical_not(np.isnan(y))\n",
    "y = y[nan_mask]\n",
    "X = X[nan_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 3600)\n",
      "(978,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10,\n",
    "                   trim_nodes=0,\n",
    "                   square_features=False):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "    \n",
    "    if trim_nodes > 0:\n",
    "        grp_mask = np.zeros_like(groups[0], dtype=bool)\n",
    "        grp_mask[trim_nodes:-trim_nodes] = True\n",
    "        X_mask = np.concatenate([grp_mask] * len(groups))\n",
    "\n",
    "        groups_trim = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for grp in groups:\n",
    "            stop_idx = start_idx + len(grp) - 2 * trim_nodes\n",
    "            groups_trim.append(np.arange(start_idx, stop_idx))\n",
    "            start_idx += len(grp) - 2 * trim_nodes\n",
    "            \n",
    "        X_trim = X[:, X_mask]\n",
    "    elif trim_nodes == 0:\n",
    "        groups_trim = [grp for grp in groups]\n",
    "        X_trim = np.copy(X)\n",
    "    else:\n",
    "        raise ValueError(\"trim_nodes must be non-negative.\")\n",
    "        \n",
    "    if square_features:\n",
    "        _n_samples, _n_features = X_trim.shape\n",
    "        X_trim = np.hstack([X_trim, np.square(X_trim)])\n",
    "        groups_trim = [np.concatenate([g, g + _n_features]) for g in groups_trim]\n",
    "\n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    \n",
    "    pipe_skopt = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LassoCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"n_alphas\": 50,\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 28,\n",
    "            \"max_iter\": 500,\n",
    "        },\n",
    "        verbose=0,\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "        target_transform_func=target_transform_func,\n",
    "        target_transform_inverse_func=target_transform_inverse_func,\n",
    "    )\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        with joblib.parallel_backend(\"dask\"):\n",
    "            pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_r2\": r2_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_r2\": r2_score(y_train, pipe_skopt.predict(X_train)),\n",
    "        }\n",
    "        \n",
    "        if ensembler is None:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.alpha_\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].alpha_\n",
    "        else:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "\n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-cf824aa2-64cc-11eb-8434-d3eefea15ecd\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-cf82289e-64cc-11eb-8434-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-cf829986-64cc-11eb-8434-d3eefea15ecd\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:38.451114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-e67b91f8-64cc-11eb-839a-15a36b1bfbe2\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-e67ad9c8-64cc-11eb-839a-15a36b1bfbe2\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-e67f284a-64cc-11eb-8460-3902087a82b7\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  1], Elapsed time:  0:00:36.155566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-fc064d2c-64cc-11eb-838f-25b39f005658\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-fc0634ec-64cc-11eb-8385-5fb860b2b25b\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-fc069a82-64cc-11eb-8385-5fb860b2b25b\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3448002232748877, tolerance: 1.0190665653150817\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  2], Elapsed time:  0:00:39.661680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-13bb7f26-64cd-11eb-83ee-13686b423ee3\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0448851032697348, tolerance: 1.011467576574898\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  3], Elapsed time:  0:00:34.063066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-27f5722c-64cd-11eb-8463-95db7c851e5b\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-27f646f8-64cd-11eb-8463-95db7c851e5b\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-27fadd08-64cd-11eb-83a1-c5a7c7946784\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  4], Elapsed time:  0:00:37.359213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-3e497392-64cd-11eb-83cb-4b30a3f64a12\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:35.410531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-535bd2e8-64cd-11eb-8412-55fd59a9d7bf\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-535965de-64cd-11eb-8412-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-535f89e6-64cd-11eb-84e7-9d78c883ede1\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  1], Elapsed time:  0:00:34.770156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-6831e106-64cd-11eb-8381-3984f0a51ba3\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  2], Elapsed time:  0:00:36.343892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7dc03b76-64cd-11eb-8486-657134553591\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7dc0cf2e-64cd-11eb-8486-657134553591\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7dc56400-64cd-11eb-845d-b7d70bd397d3\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011007079870012149, tolerance: 0.00886624759197826\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  3], Elapsed time:  0:00:35.264151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-92de415e-64cd-11eb-83f1-7913ba57d9b9\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  4], Elapsed time:  0:00:44.550368\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "trim_nodes = 0\n",
    "results[f\"bagging_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=5, n_repeats=1, power_transformer=False,\n",
    "    shuffle=False,\n",
    "    trim_nodes=trim_nodes, square_features=False\n",
    ")\n",
    "\n",
    "results[f\"bagging_target_transform_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=5, n_repeats=1, power_transformer=False,\n",
    "    shuffle=False,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    "    trim_nodes=trim_nodes, square_features=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bagging_pure_lasso_trim0', 'bagging_target_transform_pure_lasso_trim0'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mae bagging_pure_lasso_trim0 1.572916597914582\n",
      "test_mae bagging_target_transform_pure_lasso_trim0 1.492790013136703\n",
      "\n",
      "test_r2 bagging_pure_lasso_trim0 0.5442971561710012\n",
      "test_r2 bagging_target_transform_pure_lasso_trim0 0.5711707567559646\n",
      "\n",
      "train_mae bagging_pure_lasso_trim0 1.2856122810257329\n",
      "train_mae bagging_target_transform_pure_lasso_trim0 1.1632404015259072\n",
      "\n",
      "train_r2 bagging_pure_lasso_trim0 0.715749817450492\n",
      "train_r2 bagging_target_transform_pure_lasso_trim0 0.7148864643896216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in [\"test_mae\", \"test_r2\", \"train_mae\", \"train_r2\"]:\n",
    "    for key, res in results.items():\n",
    "        mean_metric = [cvr[metric] for cvr in res[0].values()]\n",
    "        print(metric, key, np.mean(mean_metric))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hbn_regression_pure_lasso.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
