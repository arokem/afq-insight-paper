{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev460469908\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/camcan_data\",\n",
    "    target_cols=[\"age\"],\n",
    "    index_col=\"Observations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641, 3600)\n",
      "(652,)\n",
      "641\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_csv(\"../data/raw/camcan_data/subjects.csv\")\n",
    "df_y.head()\n",
    "df_y = df_y[[\"Observations\", \"age\"]]\n",
    "df_y = df_y.set_index(\"Observations\", drop=True)\n",
    "df_subs = pd.DataFrame(index=subjects)\n",
    "df_subs = df_subs.merge(df_y, how=\"left\", left_index=True, right_index=True)\n",
    "y = df_subs[\"age\"].astype(np.float64).values\n",
    "nan_mask = np.logical_not(np.isnan(y))\n",
    "y = y[nan_mask]\n",
    "X = X[nan_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 3600)\n",
      "(640,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([26., 58., 72., 68., 76., 64., 71., 74., 86., 45.]),\n",
       " array([18., 25., 32., 39., 46., 53., 60., 67., 74., 81., 88.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   target_transform_func=None,\n",
    "                   target_transform_inverse_func=None,\n",
    "                   n_estimators=10,\n",
    "                   trim_nodes=0,\n",
    "                   square_features=False):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "        \n",
    "    if trim_nodes > 0:\n",
    "        grp_mask = np.zeros_like(groups[0], dtype=bool)\n",
    "        grp_mask[trim_nodes:-trim_nodes] = True\n",
    "        X_mask = np.concatenate([grp_mask] * len(groups))\n",
    "\n",
    "        groups_trim = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for grp in groups:\n",
    "            stop_idx = start_idx + len(grp) - 2 * trim_nodes\n",
    "            groups_trim.append(np.arange(start_idx, stop_idx))\n",
    "            start_idx += len(grp) - 2 * trim_nodes\n",
    "            \n",
    "        X_trim = X[:, X_mask]\n",
    "    elif trim_nodes == 0:\n",
    "        groups_trim = [grp for grp in groups]\n",
    "        X_trim = np.copy(X)\n",
    "    else:\n",
    "        raise ValueError(\"trim_nodes must be non-negative.\")\n",
    "        \n",
    "    if square_features:\n",
    "        _n_samples, _n_features = X_trim.shape\n",
    "        X_trim = np.hstack([X_trim, np.square(X_trim)])\n",
    "        groups_trim = [np.concatenate([g, g + _n_features]) for g in groups_trim]\n",
    "    \n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    pipe_skopt = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LassoCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"n_alphas\": 50,\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 10,\n",
    "            \"max_iter\": 500,\n",
    "        },\n",
    "        verbose=0,\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "        target_transform_func=target_transform_func,\n",
    "        target_transform_inverse_func=target_transform_inverse_func,\n",
    "    )\n",
    "    \n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_mae\": median_absolute_error(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_mae\": median_absolute_error(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_r2\": r2_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_r2\": r2_score(y_train, pipe_skopt.predict(X_train)),\n",
    "        }\n",
    "        \n",
    "        if ensembler is None:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].regressor_.alpha_\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].coef_\n",
    "                cv_results[cv_idx][\"alpha\"] = pipe_skopt.named_steps[\"estimate\"].alpha_\n",
    "        else:\n",
    "            if ((target_transform_func is not None)\n",
    "                or (target_transform_inverse_func is not None)):\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].regressor_.estimators_\n",
    "                ]\n",
    "            else:\n",
    "                cv_results[cv_idx][\"coefs\"] = [\n",
    "                    est.coef_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "                cv_results[cv_idx][\"alpha\"] = [\n",
    "                    est.alpha_ for est\n",
    "                    in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "                ]\n",
    "        \n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:01.106642\n",
      "CV index [  1], Elapsed time:  0:00:01.078033\n",
      "CV index [  2], Elapsed time:  0:00:01.218096\n",
      "CV index [  3], Elapsed time:  0:00:01.093290\n",
      "CV index [  4], Elapsed time:  0:00:01.360955\n",
      "CV index [  0], Elapsed time:  0:00:01.190571\n",
      "CV index [  1], Elapsed time:  0:00:01.426561\n",
      "CV index [  2], Elapsed time:  0:00:01.940823\n",
      "CV index [  3], Elapsed time:  0:00:01.207025\n",
      "CV index [  4], Elapsed time:  0:00:01.014964\n"
     ]
    }
   ],
   "source": [
    "trim_nodes = 0\n",
    "\n",
    "results[f\"bagging_target_transform_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=5, n_repeats=1, power_transformer=PCA,\n",
    "    shuffle=False,\n",
    "    target_transform_func=np.log, target_transform_inverse_func=np.exp,\n",
    "    trim_nodes=trim_nodes, square_features=False,\n",
    ")\n",
    "\n",
    "results[f\"bagging_pure_lasso_trim{trim_nodes}\"] = get_cv_results(\n",
    "    n_splits=5, n_repeats=1, power_transformer=PCA,\n",
    "    shuffle=False,\n",
    "    trim_nodes=trim_nodes, square_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_target_transform_pure_lasso_trim0 mean MAE 6.653874056511265\n",
      "bagging_target_transform_pure_lasso_trim0 std MAE 0.4597724354063769\n",
      "bagging_target_transform_pure_lasso_trim0 mean R2 0.5112274921433742\n",
      "bagging_target_transform_pure_lasso_trim0 std R2 0.3319836863791796\n",
      "bagging_pure_lasso_trim0 mean MAE 5.842818896995505\n",
      "bagging_pure_lasso_trim0 std MAE 0.3128799186367997\n",
      "bagging_pure_lasso_trim0 mean R2 0.7381611345246745\n",
      "bagging_pure_lasso_trim0 std R2 0.03116437626873482\n"
     ]
    }
   ],
   "source": [
    "for key, res in results.items():\n",
    "    test_mae = [cvr[\"test_mae\"] for cvr in res[0].values()]\n",
    "    train_mae = [cvr[\"train_mae\"] for cvr in res[0].values()]\n",
    "    test_r2 = [cvr[\"test_r2\"] for cvr in res[0].values()]\n",
    "    train_r2 = [cvr[\"train_r2\"] for cvr in res[0].values()]\n",
    "\n",
    "    print(key, \"mean MAE\", np.mean(test_mae))\n",
    "    print(key, \"std MAE\", np.std(test_mae))\n",
    "    print(key, \"mean R2\", np.mean(test_r2))\n",
    "    print(key, \"std R2\", np.std(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"camcan_regression_pcr_lasso.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
