{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:34895\n",
      "distributed.scheduler - INFO -   dashboard at:            127.0.0.1:8787\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33265'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35111'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41469'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36331'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33751'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45999'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36413'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36277'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42049'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36035'\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:43087', name: 7, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43087\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:41205', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41205\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38217', name: 6, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38217\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39643', name: 8, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39643\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:37269', name: 1, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37269\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:38771', name: 4, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38771\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:46821', name: 2, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46821\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:36337', name: 9, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36337\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:45681', name: 0, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45681\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:39177', name: 5, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39177\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-d0c997d2-64c9-11eb-b7fa-0d8cbfc15608\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import logging\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=10,\n",
    "    threads_per_worker=8,\n",
    "    silence_logs=logging.DEBUG\n",
    ")\n",
    "\n",
    "client = Client(cluster, heartbeat_interval=10000)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcp://127.0.0.1:34895'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scheduler_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9.dev460469908\n"
     ]
    }
   ],
   "source": [
    "import afqinsight as afqi\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "print(afqi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups, columns, subjects, classes = afqi.load_afq_data(\n",
    "    \"../data/raw/als_data\",\n",
    "    target_cols=[\"class\"],\n",
    "    label_encode_cols=[\"class\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyafq_bundles = [\n",
    "    c for c in columns\n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "pyafq_bundles = [\n",
    "    [c] for c in np.unique([col[1] for col in pyafq_bundles])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pyafq_bundles = afqi.select_groups(\n",
    "    X,\n",
    "    pyafq_bundles,\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 16000)\n",
      "(48, 14400)\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(len(label_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    c for c in columns\n",
    "    if c[1] not in [\"Right Cingulum Hippocampus\", \"Left Cingulum Hippocampus\"]\n",
    "]\n",
    "label_sets = afqi.multicol2sets(pd.MultiIndex.from_tuples(columns, names=[\"metric\", \"tractID\", \"nodeID\"]))\n",
    "\n",
    "X_md_fa = afqi.select_groups(\n",
    "    X_pyafq_bundles,\n",
    "    [[\"fa\"], [\"md\"]],\n",
    "    label_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 16000)\n",
      "(48, 14400)\n",
      "(48, 3600)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_pyafq_bundles.shape)\n",
    "print(X_md_fa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_md_fa = groups[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(n_repeats=5, n_splits=10,\n",
    "                   power_transformer=False, \n",
    "                   shuffle=False,\n",
    "                   ensembler=None,\n",
    "                   n_estimators=10,\n",
    "                   trim_nodes=0,\n",
    "                   square_features=False):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng()\n",
    "        y_fit = rng.permutation(y)\n",
    "    else:\n",
    "        y_fit = np.copy(y)\n",
    "\n",
    "    if trim_nodes > 0:\n",
    "        grp_mask = np.zeros_like(groups_md_fa[0], dtype=bool)\n",
    "        grp_mask[trim_nodes:-trim_nodes] = True\n",
    "        X_mask = np.concatenate([grp_mask] * len(groups_md_fa))\n",
    "\n",
    "        groups_trim = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for grp in groups_md_fa:\n",
    "            stop_idx = start_idx + len(grp) - 2 * trim_nodes\n",
    "            groups_trim.append(np.arange(start_idx, stop_idx))\n",
    "            start_idx += len(grp) - 2 * trim_nodes\n",
    "            \n",
    "        X_trim = X_md_fa[:, X_mask]\n",
    "    elif trim_nodes == 0:\n",
    "        groups_trim = [grp for grp in groups_md_fa]\n",
    "        X_trim = np.copy(X_md_fa)\n",
    "    else:\n",
    "        raise ValueError(\"trim_nodes must be non-negative.\")\n",
    "        \n",
    "    if square_features:\n",
    "        _n_samples, _n_features = X_trim.shape\n",
    "        X_trim = np.hstack([X_trim, np.square(X_trim)])\n",
    "        groups_trim = [np.concatenate([g, g + _n_features]) for g in groups_trim]\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=1729\n",
    "    )\n",
    "\n",
    "    cv_results = {}\n",
    "    pipe_skopt = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        power_transformer=power_transformer,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LogisticRegressionCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"Cs\": 50,\n",
    "            \"penalty\": \"l1\",\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 10,\n",
    "            \"solver\": \"saga\",\n",
    "            \"max_iter\": 500,\n",
    "        },\n",
    "        verbose=0,\n",
    "        ensemble_meta_estimator=ensembler,\n",
    "        ensemble_meta_estimator_kwargs={\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"n_jobs\": 1,\n",
    "            \"oob_score\": True,\n",
    "            \"random_state\": 1729,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(X_trim, y_fit)):\n",
    "        start = datetime.now()\n",
    "\n",
    "        X_train, X_test = X_trim[train_idx], X_trim[test_idx]\n",
    "        y_train, y_test = y_fit[train_idx], y_fit[test_idx]\n",
    "\n",
    "        with joblib.parallel_backend(\"dask\"):\n",
    "            pipe_skopt.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[cv_idx] = {\n",
    "            \"pipeline\": pipe_skopt,\n",
    "            \"train_idx\": train_idx,\n",
    "            \"test_idx\": test_idx,\n",
    "            \"y_prob\": pipe_skopt.predict_proba(X_test)[:, 1],\n",
    "            \"y_pred\": pipe_skopt.predict(X_test),\n",
    "            \"y_true\": y_test,\n",
    "            \"test_accuracy\": accuracy_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_accuracy\": accuracy_score(y_train, pipe_skopt.predict(X_train)),\n",
    "            \"test_roc_auc\": roc_auc_score(y_test, pipe_skopt.predict(X_test)),\n",
    "            \"train_roc_auc\": roc_auc_score(y_train, pipe_skopt.predict(X_train)),\n",
    "        }\n",
    "        if ensembler is not None:\n",
    "            cv_results[cv_idx][\"coefs\"] = [\n",
    "                est.coef_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "            cv_results[cv_idx][\"C\"] = [\n",
    "                est.C_ for est\n",
    "                in pipe_skopt.named_steps[\"estimate\"].estimators_\n",
    "            ]\n",
    "        else:\n",
    "            cv_results[cv_idx][\"coefs\"] = pipe_skopt.named_steps[\"estimate\"].coef_\n",
    "            cv_results[cv_idx][\"C\"] = pipe_skopt.named_steps[\"estimate\"].C_\n",
    "        \n",
    "        print(f\"CV index [{cv_idx:3d}], Elapsed time: \", datetime.now() - start)\n",
    "        \n",
    "    return cv_results, y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-6120f84a-64cb-11eb-b835-73a50fbfcb64\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  0], Elapsed time:  0:00:07.851499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  1], Elapsed time:  0:00:07.810273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  2], Elapsed time:  0:00:08.824207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-6fc0b664-64cb-11eb-b83d-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-6fbe95d8-64cb-11eb-b83d-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  3], Elapsed time:  0:00:08.840997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  4], Elapsed time:  0:00:08.298693\n",
      "CV index [  5], Elapsed time:  0:00:07.926956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7eb04528-64cb-11eb-b838-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7eb01d9e-64cb-11eb-b838-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Receive client connection: Client-worker-7eb3742c-64cb-11eb-b838-42010a8a0002\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  6], Elapsed time:  0:00:09.734925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  7], Elapsed time:  0:00:07.832069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-worker-892b3012-64cb-11eb-b839-1b3e903af6f1\n",
      "distributed.core - INFO - Starting established connection\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV index [  8], Elapsed time:  0:00:08.424053\n",
      "CV index [  9], Elapsed time:  0:00:08.147017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "results[f\"pure_lasso_trim0\"] = get_cv_results(\n",
    "    n_splits=10, n_repeats=1, power_transformer=False, shuffle=False,\n",
    "    trim_nodes=0, square_features=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pure_lasso_trim0'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pure_lasso_trim0 test  acc 0.76\n",
      "pure_lasso_trim0 train acc 0.9767441860465116\n",
      "pure_lasso_trim0 test  auc 0.7583333333333333\n",
      "pure_lasso_trim0 train auc 0.9768398268398268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, res in results.items():\n",
    "    test_accuracies = [cvr[\"test_accuracy\"] for cvr in res[0].values()]\n",
    "    train_accuracies = [cvr[\"train_accuracy\"] for cvr in res[0].values()]\n",
    "    test_auc = [cvr[\"test_roc_auc\"] for cvr in res[0].values()]\n",
    "    train_auc = [cvr[\"train_roc_auc\"] for cvr in res[0].values()]\n",
    "    \n",
    "    print(key, \"test  acc\", np.mean(test_accuracies))\n",
    "    print(key, \"train acc\", np.mean(train_accuracies))\n",
    "    print(key, \"test  auc\", np.mean(test_auc))\n",
    "    print(key, \"train auc\", np.mean(train_auc))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"als_classify_pure_lasso.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
